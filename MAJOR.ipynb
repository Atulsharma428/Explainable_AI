{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage import feature\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images and labels from a dataset folder\n",
    "def load_dataset(dataset_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_names = os.listdir(dataset_path)\n",
    "    for label in label_names:\n",
    "        label_path = os.path.join(dataset_path, label)\n",
    "        for image_name in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = 'fish_dt'  # Replace with your actual dataset path\n",
    "images, labels = load_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images(images, labels, augment_size=1000):\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    for image, label in zip(images, labels):\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        label = np.expand_dims(label, axis=0)\n",
    "        aug_iter = datagen.flow(image, batch_size=1)\n",
    "        for i in range(augment_size):\n",
    "            augmented_image = aug_iter.next()[0].astype(np.uint8)\n",
    "            augmented_images.append(augmented_image)\n",
    "            augmented_labels.append(label)\n",
    "    return np.array(augmented_images), np.array(augmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to grayscale\n",
    "gray_images = [cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LBP\n",
    "def apply_lbp(image, num_points=24, radius=8):\n",
    "    lbp = local_binary_pattern(image, num_points, radius, method='uniform')\n",
    "    return lbp\n",
    "\n",
    "# Apply LDP\n",
    "def apply_ldp(image):\n",
    "    gx = cv2.Sobel(image, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(image, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    magnitude, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)\n",
    "    angle_bins = np.int32(8 * angle / 360)  # Quantize the angle to 8 bins\n",
    "    return angle_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute histogram\n",
    "def compute_histogram(image, bins=16):\n",
    "    hist, _ = np.histogram(image.ravel(), bins=bins, range=(0, bins))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)  # Normalize the histogram\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply BWT (Block-wise Truncation)\n",
    "def apply_bwt(image, blocks=(8, 8)):\n",
    "    features = []\n",
    "    h, w = image.shape\n",
    "    (bx, by) = blocks\n",
    "    xsteps = np.linspace(0, w, bx + 1, dtype=int)\n",
    "    ysteps = np.linspace(0, h, by + 1, dtype=int)\n",
    "    for i in range(1, len(ysteps)):\n",
    "        for j in range(1, len(xsteps)):\n",
    "            block = image[ysteps[i-1]:ysteps[i], xsteps[j-1]:xsteps[j]]\n",
    "            hist = np.histogram(block, bins=256, range=(0, 256))[0] / (block.shape[0] * block.shape[1])\n",
    "            features.extend(hist)\n",
    "    return features\n",
    "\n",
    "# Apply Hough Transform\n",
    "def apply_hough(image):\n",
    "    edges = cv2.Canny(image, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)\n",
    "    return len(lines) if lines is not None else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from the dataset\n",
    "lbp_features_list = []\n",
    "ldp_features_list = []\n",
    "bwt_features_list = []\n",
    "hough_features_list = []\n",
    "\n",
    "for gray_image in gray_images:\n",
    "    # Apply LBP\n",
    "    lbp_image = apply_lbp(gray_image)\n",
    "    lbp_hist_features = compute_histogram(lbp_image, bins=16)\n",
    "    lbp_features_list.append(lbp_hist_features)\n",
    "    \n",
    "    # Apply LDP\n",
    "    ldp_image = apply_ldp(gray_image)\n",
    "    ldp_hist_features = compute_histogram(ldp_image, bins=16)\n",
    "    ldp_features_list.append(ldp_hist_features)\n",
    "    \n",
    "    # Apply BWT\n",
    "    bwt_features = apply_bwt(gray_image)\n",
    "    bwt_features_list.append(bwt_features)\n",
    "    \n",
    "    # Apply Hough Transform\n",
    "    hough_features = apply_hough(gray_image)\n",
    "    hough_features_list.append(hough_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "numeric_labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate classifiers\n",
    "def train_and_evaluate_model(X_train, X_test, y_train, y_test, classifier):\n",
    "    clf = classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"Classifier: {clf.__class__.__name__}\")\n",
    "    print(f\"Classification Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LBP Features\n",
      "Classifier: SVC\n",
      "Classification Accuracy: 0.8714285714285714\n",
      "Precision: 0.7593877551020408\n",
      "Recall: 0.8714285714285714\n",
      "F1 Score: 0.8115594329334788\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        45\n",
      "           1       0.87      1.00      0.93       305\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.44      0.50      0.47       350\n",
      "weighted avg       0.76      0.87      0.81       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Classification Accuracy: 0.8885714285714286\n",
      "Precision: 0.8704978354978355\n",
      "Recall: 0.8885714285714286\n",
      "F1 Score: 0.8693363329583802\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.29      0.40        45\n",
      "           1       0.90      0.98      0.94       305\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.78      0.63      0.67       350\n",
      "weighted avg       0.87      0.89      0.87       350\n",
      "\n",
      "Classifier: GradientBoostingClassifier\n",
      "Classification Accuracy: 0.8942857142857142\n",
      "Precision: 0.8817579127459367\n",
      "Recall: 0.8942857142857142\n",
      "F1 Score: 0.8715557461343656\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.27      0.39        45\n",
      "           1       0.90      0.99      0.94       305\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.83      0.63      0.67       350\n",
      "weighted avg       0.88      0.89      0.87       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: AdaBoostClassifier\n",
      "Classification Accuracy: 0.8571428571428571\n",
      "Precision: 0.8435374149659864\n",
      "Recall: 0.8571428571428571\n",
      "F1 Score: 0.8493663594470046\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.33      0.38        45\n",
      "           1       0.90      0.93      0.92       305\n",
      "\n",
      "    accuracy                           0.86       350\n",
      "   macro avg       0.67      0.63      0.65       350\n",
      "weighted avg       0.84      0.86      0.85       350\n",
      "\n",
      "Classifier: DecisionTreeClassifier\n",
      "Classification Accuracy: 0.8085714285714286\n",
      "Precision: 0.8241473616473616\n",
      "Recall: 0.8085714285714286\n",
      "F1 Score: 0.8158394018626964\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.36      0.32        45\n",
      "           1       0.90      0.88      0.89       305\n",
      "\n",
      "    accuracy                           0.81       350\n",
      "   macro avg       0.60      0.62      0.61       350\n",
      "weighted avg       0.82      0.81      0.82       350\n",
      "\n",
      "Classifier: LogisticRegression\n",
      "Classification Accuracy: 0.8685714285714285\n",
      "Precision: 0.7590667212443717\n",
      "Recall: 0.8685714285714285\n",
      "F1 Score: 0.8101354303189165\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        45\n",
      "           1       0.87      1.00      0.93       305\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.44      0.50      0.46       350\n",
      "weighted avg       0.76      0.87      0.81       350\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Classification Accuracy: 0.7885714285714286\n",
      "Precision: 0.8411428571428572\n",
      "Recall: 0.7885714285714286\n",
      "F1 Score: 0.8095320197044333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.51      0.38        45\n",
      "           1       0.92      0.83      0.87       305\n",
      "\n",
      "    accuracy                           0.79       350\n",
      "   macro avg       0.61      0.67      0.63       350\n",
      "weighted avg       0.84      0.79      0.81       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets for LBP features\n",
    "X_train, X_test, y_train, y_test = train_test_split(lbp_features_list, numeric_labels, test_size=0.2, random_state=42)\n",
    "print(\"Evaluating LBP Features\")\n",
    "for clf in [SVC(kernel='linear'), RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            GradientBoostingClassifier(n_estimators=100, random_state=42), AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "            DecisionTreeClassifier(random_state=42), LogisticRegression(), GaussianNB()]:\n",
    "    train_and_evaluate_model(X_train, X_test, y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating LDP Features\n",
      "Classifier: SVC\n",
      "Classification Accuracy: 0.8714285714285714\n",
      "Precision: 0.7593877551020408\n",
      "Recall: 0.8714285714285714\n",
      "F1 Score: 0.8115594329334788\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        45\n",
      "           1       0.87      1.00      0.93       305\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.44      0.50      0.47       350\n",
      "weighted avg       0.76      0.87      0.81       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Classification Accuracy: 0.8628571428571429\n",
      "Precision: 0.806954335986594\n",
      "Recall: 0.8628571428571429\n",
      "F1 Score: 0.8209641751437418\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.07      0.11        45\n",
      "           1       0.88      0.98      0.93       305\n",
      "\n",
      "    accuracy                           0.86       350\n",
      "   macro avg       0.61      0.52      0.52       350\n",
      "weighted avg       0.81      0.86      0.82       350\n",
      "\n",
      "Classifier: GradientBoostingClassifier\n",
      "Classification Accuracy: 0.8657142857142858\n",
      "Precision: 0.812625313283208\n",
      "Recall: 0.8657142857142858\n",
      "F1 Score: 0.8226806700633652\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.07      0.11        45\n",
      "           1       0.88      0.98      0.93       305\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.63      0.53      0.52       350\n",
      "weighted avg       0.81      0.87      0.82       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: AdaBoostClassifier\n",
      "Classification Accuracy: 0.8485714285714285\n",
      "Precision: 0.7715126050420169\n",
      "Recall: 0.8485714285714285\n",
      "F1 Score: 0.8044981375213933\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.02      0.04        45\n",
      "           1       0.87      0.97      0.92       305\n",
      "\n",
      "    accuracy                           0.85       350\n",
      "   macro avg       0.49      0.50      0.48       350\n",
      "weighted avg       0.77      0.85      0.80       350\n",
      "\n",
      "Classifier: DecisionTreeClassifier\n",
      "Classification Accuracy: 0.7714285714285715\n",
      "Precision: 0.7914153642967202\n",
      "Recall: 0.7714285714285715\n",
      "F1 Score: 0.780952380952381\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.22      0.20        45\n",
      "           1       0.88      0.85      0.87       305\n",
      "\n",
      "    accuracy                           0.77       350\n",
      "   macro avg       0.53      0.54      0.53       350\n",
      "weighted avg       0.79      0.77      0.78       350\n",
      "\n",
      "Classifier: LogisticRegression\n",
      "Classification Accuracy: 0.8714285714285714\n",
      "Precision: 0.7593877551020408\n",
      "Recall: 0.8714285714285714\n",
      "F1 Score: 0.8115594329334788\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        45\n",
      "           1       0.87      1.00      0.93       305\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.44      0.50      0.47       350\n",
      "weighted avg       0.76      0.87      0.81       350\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Classification Accuracy: 0.8314285714285714\n",
      "Precision: 0.8007320319432121\n",
      "Recall: 0.8314285714285714\n",
      "F1 Score: 0.8140856499904805\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.16      0.19        45\n",
      "           1       0.88      0.93      0.91       305\n",
      "\n",
      "    accuracy                           0.83       350\n",
      "   macro avg       0.57      0.54      0.55       350\n",
      "weighted avg       0.80      0.83      0.81       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets for LDP features\n",
    "X_train, X_test, y_train, y_test = train_test_split(ldp_features_list, numeric_labels, test_size=0.2, random_state=42)\n",
    "print(\"\\nEvaluating LDP Features\")\n",
    "for clf in [SVC(kernel='linear'), RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            GradientBoostingClassifier(n_estimators=100, random_state=42), AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "            DecisionTreeClassifier(random_state=42), LogisticRegression(), GaussianNB()]:\n",
    "    train_and_evaluate_model(X_train, X_test, y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Combined LBP and LDP Features\n",
      "Classifier: SVC\n",
      "Classification Accuracy: 0.8714285714285714\n",
      "Precision: 0.7593877551020408\n",
      "Recall: 0.8714285714285714\n",
      "F1 Score: 0.8115594329334788\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        45\n",
      "           1       0.87      1.00      0.93       305\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.44      0.50      0.47       350\n",
      "weighted avg       0.76      0.87      0.81       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Classification Accuracy: 0.8942857142857142\n",
      "Precision: 0.8817579127459367\n",
      "Recall: 0.8942857142857142\n",
      "F1 Score: 0.8715557461343656\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.27      0.39        45\n",
      "           1       0.90      0.99      0.94       305\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.83      0.63      0.67       350\n",
      "weighted avg       0.88      0.89      0.87       350\n",
      "\n",
      "Classifier: GradientBoostingClassifier\n",
      "Classification Accuracy: 0.8914285714285715\n",
      "Precision: 0.8750325662179765\n",
      "Recall: 0.8914285714285715\n",
      "F1 Score: 0.8737432914089066\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.31      0.42        45\n",
      "           1       0.91      0.98      0.94       305\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.79      0.64      0.68       350\n",
      "weighted avg       0.88      0.89      0.87       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: AdaBoostClassifier\n",
      "Classification Accuracy: 0.88\n",
      "Precision: 0.8713237198860202\n",
      "Recall: 0.88\n",
      "F1 Score: 0.8749230404925408\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.44      0.49        45\n",
      "           1       0.92      0.94      0.93       305\n",
      "\n",
      "    accuracy                           0.88       350\n",
      "   macro avg       0.73      0.69      0.71       350\n",
      "weighted avg       0.87      0.88      0.87       350\n",
      "\n",
      "Classifier: DecisionTreeClassifier\n",
      "Classification Accuracy: 0.8142857142857143\n",
      "Precision: 0.8327259475218659\n",
      "Recall: 0.8142857142857143\n",
      "F1 Score: 0.8226936454675756\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.40      0.36        45\n",
      "           1       0.91      0.88      0.89       305\n",
      "\n",
      "    accuracy                           0.81       350\n",
      "   macro avg       0.61      0.64      0.62       350\n",
      "weighted avg       0.83      0.81      0.82       350\n",
      "\n",
      "Classifier: LogisticRegression\n",
      "Classification Accuracy: 0.8714285714285714\n",
      "Precision: 0.8255336617405583\n",
      "Recall: 0.8714285714285714\n",
      "F1 Score: 0.8168471911262957\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.02      0.04        45\n",
      "           1       0.87      1.00      0.93       305\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.69      0.51      0.49       350\n",
      "weighted avg       0.83      0.87      0.82       350\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Classification Accuracy: 0.7742857142857142\n",
      "Precision: 0.8373875661375662\n",
      "Recall: 0.7742857142857142\n",
      "F1 Score: 0.799016149068323\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.51      0.37        45\n",
      "           1       0.92      0.81      0.86       305\n",
      "\n",
      "    accuracy                           0.77       350\n",
      "   macro avg       0.60      0.66      0.62       350\n",
      "weighted avg       0.84      0.77      0.80       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine LBP and LDP features\n",
    "combined_features_list = [np.hstack((lbp, ldp)) for lbp, ldp in zip(lbp_features_list, ldp_features_list)]\n",
    "\n",
    "# Split the data into training and testing sets for combined features\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features_list, numeric_labels, test_size=0.2, random_state=42)\n",
    "print(\"\\nEvaluating Combined LBP and LDP Features\")\n",
    "for clf in [SVC(kernel='linear'), RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            GradientBoostingClassifier(n_estimators=100, random_state=42), AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "            DecisionTreeClassifier(random_state=42), LogisticRegression(), GaussianNB()]:\n",
    "    train_and_evaluate_model(X_train, X_test, y_train, y_test, clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating BWT Features\n",
      "Classifier: SVC\n",
      "Classification Accuracy: 0.8828571428571429\n",
      "Precision: 0.8635626643295355\n",
      "Recall: 0.8828571428571429\n",
      "F1 Score: 0.8669803427468967\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.31      0.41        45\n",
      "           1       0.90      0.97      0.94       305\n",
      "\n",
      "    accuracy                           0.88       350\n",
      "   macro avg       0.74      0.64      0.67       350\n",
      "weighted avg       0.86      0.88      0.87       350\n",
      "\n",
      "Classifier: RandomForestClassifier\n",
      "Classification Accuracy: 0.8885714285714286\n",
      "Precision: 0.901204318936877\n",
      "Recall: 0.8885714285714286\n",
      "F1 Score: 0.8493143944789009\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.13      0.24        45\n",
      "           1       0.89      1.00      0.94       305\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.94      0.57      0.59       350\n",
      "weighted avg       0.90      0.89      0.85       350\n",
      "\n",
      "Classifier: GradientBoostingClassifier\n",
      "Classification Accuracy: 0.8942857142857142\n",
      "Precision: 0.8842687074829931\n",
      "Recall: 0.8942857142857142\n",
      "F1 Score: 0.8690695908708018\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.24      0.37        45\n",
      "           1       0.90      0.99      0.94       305\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.84      0.62      0.66       350\n",
      "weighted avg       0.88      0.89      0.87       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: AdaBoostClassifier\n",
      "Classification Accuracy: 0.8942857142857142\n",
      "Precision: 0.8810115350488021\n",
      "Recall: 0.8942857142857142\n",
      "F1 Score: 0.8834096449092843\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.40      0.49        45\n",
      "           1       0.92      0.97      0.94       305\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.78      0.68      0.72       350\n",
      "weighted avg       0.88      0.89      0.88       350\n",
      "\n",
      "Classifier: DecisionTreeClassifier\n",
      "Classification Accuracy: 0.8171428571428572\n",
      "Precision: 0.8205703853060079\n",
      "Recall: 0.8171428571428572\n",
      "F1 Score: 0.8188296829029095\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.31      0.30        45\n",
      "           1       0.90      0.89      0.89       305\n",
      "\n",
      "    accuracy                           0.82       350\n",
      "   macro avg       0.60      0.60      0.60       350\n",
      "weighted avg       0.82      0.82      0.82       350\n",
      "\n",
      "Classifier: LogisticRegression\n",
      "Classification Accuracy: 0.8942857142857142\n",
      "Precision: 0.894873949579832\n",
      "Recall: 0.8942857142857142\n",
      "F1 Score: 0.8635175677036143\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.20      0.33        45\n",
      "           1       0.89      1.00      0.94       305\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.90      0.60      0.63       350\n",
      "weighted avg       0.89      0.89      0.86       350\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Classification Accuracy: 0.7657142857142857\n",
      "Precision: 0.8490135347278205\n",
      "Recall: 0.7657142857142857\n",
      "F1 Score: 0.7957819297931938\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.60      0.40        45\n",
      "           1       0.93      0.79      0.85       305\n",
      "\n",
      "    accuracy                           0.77       350\n",
      "   macro avg       0.61      0.70      0.63       350\n",
      "weighted avg       0.85      0.77      0.80       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets for BWT features\n",
    "X_train, X_test, y_train, y_test = train_test_split(bwt_features_list, numeric_labels, test_size=0.2, random_state=42)\n",
    "print(\"\\nEvaluating BWT Features\")\n",
    "for clf in [SVC(kernel='linear'), RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            GradientBoostingClassifier(n_estimators=100, random_state=42), AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "            DecisionTreeClassifier(random_state=42), LogisticRegression(), GaussianNB()]:\n",
    "    train_and_evaluate_model(X_train, X_test, y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1400, 16384)\n",
      "Shape of y_train: (1400,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", np.array(X_train).shape)\n",
    "print(\"Shape of y_train:\", np.array(y_train).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hough_features_list = np.array(hough_features_list).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Combined LBP, LDP, BWT, and Hough Features\n",
      "Classifier: SVC\n",
      "Classification Accuracy: 0.8914285714285715\n",
      "Precision: 0.8792048885486038\n",
      "Recall: 0.8914285714285715\n",
      "F1 Score: 0.8826465201465201\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.42      0.50        45\n",
      "           1       0.92      0.96      0.94       305\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.77      0.69      0.72       350\n",
      "weighted avg       0.88      0.89      0.88       350\n",
      "\n",
      "Classifier: RandomForestClassifier\n",
      "Classification Accuracy: 0.8942857142857142\n",
      "Precision: 0.9057226399331663\n",
      "Recall: 0.8942857142857142\n",
      "F1 Score: 0.8604081870711598\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.18      0.30        45\n",
      "           1       0.89      1.00      0.94       305\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.95      0.59      0.62       350\n",
      "weighted avg       0.91      0.89      0.86       350\n",
      "\n",
      "Classifier: GradientBoostingClassifier\n",
      "Classification Accuracy: 0.8942857142857142\n",
      "Precision: 0.8793870763382959\n",
      "Recall: 0.8942857142857142\n",
      "F1 Score: 0.8780612846397667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.33      0.45        45\n",
      "           1       0.91      0.98      0.94       305\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.80      0.66      0.69       350\n",
      "weighted avg       0.88      0.89      0.88       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: AdaBoostClassifier\n",
      "Classification Accuracy: 0.8914285714285715\n",
      "Precision: 0.8806259986070711\n",
      "Recall: 0.8914285714285715\n",
      "F1 Score: 0.8841242358927247\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.44      0.51        45\n",
      "           1       0.92      0.96      0.94       305\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.76      0.70      0.73       350\n",
      "weighted avg       0.88      0.89      0.88       350\n",
      "\n",
      "Classifier: DecisionTreeClassifier\n",
      "Classification Accuracy: 0.8285714285714286\n",
      "Precision: 0.8349718624991523\n",
      "Recall: 0.8285714285714286\n",
      "F1 Score: 0.8316530741220018\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.38      0.36        45\n",
      "           1       0.91      0.90      0.90       305\n",
      "\n",
      "    accuracy                           0.83       350\n",
      "   macro avg       0.63      0.64      0.63       350\n",
      "weighted avg       0.83      0.83      0.83       350\n",
      "\n",
      "Classifier: LogisticRegression\n",
      "Classification Accuracy: 0.8971428571428571\n",
      "Precision: 0.8923011706394496\n",
      "Recall: 0.8971428571428571\n",
      "F1 Score: 0.8713318907969247\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.24      0.38        45\n",
      "           1       0.90      0.99      0.94       305\n",
      "\n",
      "    accuracy                           0.90       350\n",
      "   macro avg       0.87      0.62      0.66       350\n",
      "weighted avg       0.89      0.90      0.87       350\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Classification Accuracy: 0.7657142857142857\n",
      "Precision: 0.8490135347278205\n",
      "Recall: 0.7657142857142857\n",
      "F1 Score: 0.7957819297931938\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.60      0.40        45\n",
      "           1       0.93      0.79      0.85       305\n",
      "\n",
      "    accuracy                           0.77       350\n",
      "   macro avg       0.61      0.70      0.63       350\n",
      "weighted avg       0.85      0.77      0.80       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets for combined features\n",
    "combined_features_list = [np.hstack((lbp, ldp, bwt, hough)) for lbp, ldp, bwt, hough in\n",
    "                          zip(lbp_features_list, ldp_features_list, bwt_features_list, hough_features_list)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features_list, numeric_labels, test_size=0.2, random_state=42)\n",
    "print(\"\\nEvaluating Combined LBP, LDP, BWT, and Hough Features\")\n",
    "for clf in [SVC(kernel='linear'), RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            GradientBoostingClassifier(n_estimators=100, random_state=42), AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "            DecisionTreeClassifier(random_state=42), LogisticRegression(), GaussianNB()]:\n",
    "    train_and_evaluate_model(X_train, X_test, y_train, y_test, clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from RGB channels\n",
    "def extract_color_features(image):\n",
    "    channels = cv2.split(image)\n",
    "    features = []\n",
    "    for channel in channels:\n",
    "        lbp_image = apply_lbp(channel)\n",
    "        lbp_hist_features = compute_histogram(lbp_image, bins=16)\n",
    "        ldp_image = apply_ldp(channel)\n",
    "        ldp_hist_features = compute_histogram(ldp_image, bins=16)\n",
    "        features.extend(np.hstack((lbp_hist_features, ldp_hist_features)))\n",
    "    return features\n",
    "\n",
    "# Extract features from RGB channels\n",
    "rgb_features_list = [extract_color_features(image) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating RGB Channel Features\n",
      "Classifier: SVC\n",
      "Classification Accuracy: 0.8714285714285714\n",
      "Precision: 0.7593877551020408\n",
      "Recall: 0.8714285714285714\n",
      "F1 Score: 0.8115594329334788\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        45\n",
      "           1       0.87      1.00      0.93       305\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.44      0.50      0.47       350\n",
      "weighted avg       0.76      0.87      0.81       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Classification Accuracy: 0.8971428571428571\n",
      "Precision: 0.8838037342596614\n",
      "Recall: 0.8971428571428571\n",
      "F1 Score: 0.8803883813347535\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.33      0.45        45\n",
      "           1       0.91      0.98      0.94       305\n",
      "\n",
      "    accuracy                           0.90       350\n",
      "   macro avg       0.81      0.66      0.70       350\n",
      "weighted avg       0.88      0.90      0.88       350\n",
      "\n",
      "Classifier: GradientBoostingClassifier\n",
      "Classification Accuracy: 0.88\n",
      "Precision: 0.856352361265702\n",
      "Recall: 0.88\n",
      "F1 Score: 0.8580778301886792\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.24      0.34        45\n",
      "           1       0.90      0.97      0.93       305\n",
      "\n",
      "    accuracy                           0.88       350\n",
      "   macro avg       0.74      0.61      0.64       350\n",
      "weighted avg       0.86      0.88      0.86       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: AdaBoostClassifier\n",
      "Classification Accuracy: 0.8542857142857143\n",
      "Precision: 0.8445657412762677\n",
      "Recall: 0.8542857142857143\n",
      "F1 Score: 0.8489677161993656\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.36      0.39        45\n",
      "           1       0.91      0.93      0.92       305\n",
      "\n",
      "    accuracy                           0.85       350\n",
      "   macro avg       0.66      0.64      0.65       350\n",
      "weighted avg       0.84      0.85      0.85       350\n",
      "\n",
      "Classifier: DecisionTreeClassifier\n",
      "Classification Accuracy: 0.7885714285714286\n",
      "Precision: 0.8278285503326377\n",
      "Recall: 0.7885714285714286\n",
      "F1 Score: 0.8053814382896015\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.42      0.34        45\n",
      "           1       0.91      0.84      0.87       305\n",
      "\n",
      "    accuracy                           0.79       350\n",
      "   macro avg       0.60      0.63      0.61       350\n",
      "weighted avg       0.83      0.79      0.81       350\n",
      "\n",
      "Classifier: LogisticRegression\n",
      "Classification Accuracy: 0.88\n",
      "Precision: 0.8574780058651027\n",
      "Recall: 0.88\n",
      "F1 Score: 0.843343653250774\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.13      0.22        45\n",
      "           1       0.89      0.99      0.93       305\n",
      "\n",
      "    accuracy                           0.88       350\n",
      "   macro avg       0.78      0.56      0.58       350\n",
      "weighted avg       0.86      0.88      0.84       350\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Classification Accuracy: 0.7571428571428571\n",
      "Precision: 0.8470863411854103\n",
      "Recall: 0.7571428571428571\n",
      "F1 Score: 0.7893425519324802\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.60      0.39        45\n",
      "           1       0.93      0.78      0.85       305\n",
      "\n",
      "    accuracy                           0.76       350\n",
      "   macro avg       0.61      0.69      0.62       350\n",
      "weighted avg       0.85      0.76      0.79       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets for RGB features\n",
    "X_train, X_test, y_train, y_test = train_test_split(rgb_features_list, numeric_labels, test_size=0.2, random_state=42)\n",
    "print(\"\\nEvaluating RGB Channel Features\")\n",
    "for clf in [SVC(kernel='linear'), RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            GradientBoostingClassifier(n_estimators=100, random_state=42), AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "            DecisionTreeClassifier(random_state=42), LogisticRegression(), GaussianNB()]:\n",
    "    train_and_evaluate_model(X_train, X_test, y_train, y_test, clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating HSV Color Space Features\n",
      "Classifier: SVC\n",
      "Classification Accuracy: 0.8714285714285714\n",
      "Precision: 0.7593877551020408\n",
      "Recall: 0.8714285714285714\n",
      "F1 Score: 0.8115594329334788\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        45\n",
      "           1       0.87      1.00      0.93       305\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.44      0.50      0.47       350\n",
      "weighted avg       0.76      0.87      0.81       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Classification Accuracy: 0.8942857142857142\n",
      "Precision: 0.8802925989672977\n",
      "Recall: 0.8942857142857142\n",
      "F1 Score: 0.8738730657098003\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.29      0.41        45\n",
      "           1       0.90      0.98      0.94       305\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.81      0.64      0.68       350\n",
      "weighted avg       0.88      0.89      0.87       350\n",
      "\n",
      "Classifier: GradientBoostingClassifier\n",
      "Classification Accuracy: 0.9028571428571428\n",
      "Precision: 0.8916043956043956\n",
      "Recall: 0.9028571428571428\n",
      "F1 Score: 0.8905215419501132\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.40      0.51        45\n",
      "           1       0.92      0.98      0.95       305\n",
      "\n",
      "    accuracy                           0.90       350\n",
      "   macro avg       0.82      0.69      0.73       350\n",
      "weighted avg       0.89      0.90      0.89       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: AdaBoostClassifier\n",
      "Classification Accuracy: 0.8685714285714285\n",
      "Precision: 0.863642411736184\n",
      "Recall: 0.8685714285714285\n",
      "F1 Score: 0.8659430562619715\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.44      0.47        45\n",
      "           1       0.92      0.93      0.93       305\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.70      0.69      0.70       350\n",
      "weighted avg       0.86      0.87      0.87       350\n",
      "\n",
      "Classifier: DecisionTreeClassifier\n",
      "Classification Accuracy: 0.82\n",
      "Precision: 0.8283333333333333\n",
      "Recall: 0.82\n",
      "F1 Score: 0.8239930404523707\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.36      0.34        45\n",
      "           1       0.90      0.89      0.90       305\n",
      "\n",
      "    accuracy                           0.82       350\n",
      "   macro avg       0.61      0.62      0.62       350\n",
      "weighted avg       0.83      0.82      0.82       350\n",
      "\n",
      "Classifier: LogisticRegression\n",
      "Classification Accuracy: 0.8742857142857143\n",
      "Precision: 0.8491560312885962\n",
      "Recall: 0.8742857142857143\n",
      "F1 Score: 0.8233347940403155\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.04      0.08        45\n",
      "           1       0.88      1.00      0.93       305\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.77      0.52      0.51       350\n",
      "weighted avg       0.85      0.87      0.82       350\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Classification Accuracy: 0.7771428571428571\n",
      "Precision: 0.8381174806323107\n",
      "Recall: 0.7771428571428571\n",
      "F1 Score: 0.8011184715821813\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.51      0.37        45\n",
      "           1       0.92      0.82      0.86       305\n",
      "\n",
      "    accuracy                           0.78       350\n",
      "   macro avg       0.60      0.66      0.62       350\n",
      "weighted avg       0.84      0.78      0.80       350\n",
      "\n",
      "\n",
      "Evaluating LAB Color Space Features\n",
      "Classifier: SVC\n",
      "Classification Accuracy: 0.8714285714285714\n",
      "Precision: 0.7593877551020408\n",
      "Recall: 0.8714285714285714\n",
      "F1 Score: 0.8115594329334788\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        45\n",
      "           1       0.87      1.00      0.93       305\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.44      0.50      0.47       350\n",
      "weighted avg       0.76      0.87      0.81       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Classification Accuracy: 0.9028571428571428\n",
      "Precision: 0.8939508893078618\n",
      "Recall: 0.9028571428571428\n",
      "F1 Score: 0.8851106244384547\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.33      0.47        45\n",
      "           1       0.91      0.99      0.95       305\n",
      "\n",
      "    accuracy                           0.90       350\n",
      "   macro avg       0.85      0.66      0.71       350\n",
      "weighted avg       0.89      0.90      0.89       350\n",
      "\n",
      "Classifier: GradientBoostingClassifier\n",
      "Classification Accuracy: 0.9114285714285715\n",
      "Precision: 0.9048899271460247\n",
      "Recall: 0.9114285714285715\n",
      "F1 Score: 0.8978351303738585\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.40      0.54        45\n",
      "           1       0.92      0.99      0.95       305\n",
      "\n",
      "    accuracy                           0.91       350\n",
      "   macro avg       0.87      0.69      0.74       350\n",
      "weighted avg       0.90      0.91      0.90       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: AdaBoostClassifier\n",
      "Classification Accuracy: 0.8942857142857142\n",
      "Precision: 0.8846558876715244\n",
      "Recall: 0.8942857142857142\n",
      "F1 Score: 0.8878621368439749\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.47      0.53        45\n",
      "           1       0.92      0.96      0.94       305\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.77      0.71      0.74       350\n",
      "weighted avg       0.88      0.89      0.89       350\n",
      "\n",
      "Classifier: DecisionTreeClassifier\n",
      "Classification Accuracy: 0.8228571428571428\n",
      "Precision: 0.8390402817521462\n",
      "Recall: 0.8228571428571428\n",
      "F1 Score: 0.8302380952380952\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.42      0.38        45\n",
      "           1       0.91      0.88      0.90       305\n",
      "\n",
      "    accuracy                           0.82       350\n",
      "   macro avg       0.63      0.65      0.64       350\n",
      "weighted avg       0.84      0.82      0.83       350\n",
      "\n",
      "Classifier: LogisticRegression\n",
      "Classification Accuracy: 0.8742857142857143\n",
      "Precision: 0.8491560312885962\n",
      "Recall: 0.8742857142857143\n",
      "F1 Score: 0.8233347940403155\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.04      0.08        45\n",
      "           1       0.88      1.00      0.93       305\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.77      0.52      0.51       350\n",
      "weighted avg       0.85      0.87      0.82       350\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Classification Accuracy: 0.7714285714285715\n",
      "Precision: 0.8434755034089108\n",
      "Recall: 0.7714285714285715\n",
      "F1 Score: 0.7985733564680932\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.56      0.38        45\n",
      "           1       0.92      0.80      0.86       305\n",
      "\n",
      "    accuracy                           0.77       350\n",
      "   macro avg       0.61      0.68      0.62       350\n",
      "weighted avg       0.84      0.77      0.80       350\n",
      "\n",
      "\n",
      "Evaluating YCbCr Color Space Features\n",
      "Classifier: SVC\n",
      "Classification Accuracy: 0.8714285714285714\n",
      "Precision: 0.7593877551020408\n",
      "Recall: 0.8714285714285714\n",
      "F1 Score: 0.8115594329334788\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        45\n",
      "           1       0.87      1.00      0.93       305\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.44      0.50      0.47       350\n",
      "weighted avg       0.76      0.87      0.81       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Classification Accuracy: 0.9\n",
      "Precision: 0.887888026607539\n",
      "Recall: 0.9\n",
      "F1 Score: 0.8846525665511307\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.36      0.48        45\n",
      "           1       0.91      0.98      0.94       305\n",
      "\n",
      "    accuracy                           0.90       350\n",
      "   macro avg       0.82      0.67      0.71       350\n",
      "weighted avg       0.89      0.90      0.88       350\n",
      "\n",
      "Classifier: GradientBoostingClassifier\n",
      "Classification Accuracy: 0.9085714285714286\n",
      "Precision: 0.8994285714285715\n",
      "Recall: 0.9085714285714286\n",
      "F1 Score: 0.8969614512471655\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.42      0.54        45\n",
      "           1       0.92      0.98      0.95       305\n",
      "\n",
      "    accuracy                           0.91       350\n",
      "   macro avg       0.84      0.70      0.75       350\n",
      "weighted avg       0.90      0.91      0.90       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: AdaBoostClassifier\n",
      "Classification Accuracy: 0.9142857142857143\n",
      "Precision: 0.907936507936508\n",
      "Recall: 0.9142857142857143\n",
      "F1 Score: 0.9096198156682028\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.56      0.62        45\n",
      "           1       0.94      0.97      0.95       305\n",
      "\n",
      "    accuracy                           0.91       350\n",
      "   macro avg       0.83      0.76      0.79       350\n",
      "weighted avg       0.91      0.91      0.91       350\n",
      "\n",
      "Classifier: DecisionTreeClassifier\n",
      "Classification Accuracy: 0.8371428571428572\n",
      "Precision: 0.8507722007722007\n",
      "Recall: 0.8371428571428572\n",
      "F1 Score: 0.8433260583010999\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.47      0.42        45\n",
      "           1       0.92      0.89      0.91       305\n",
      "\n",
      "    accuracy                           0.84       350\n",
      "   macro avg       0.65      0.68      0.66       350\n",
      "weighted avg       0.85      0.84      0.84       350\n",
      "\n",
      "Classifier: LogisticRegression\n",
      "Classification Accuracy: 0.8771428571428571\n",
      "Precision: 0.8923234811165845\n",
      "Recall: 0.8771428571428571\n",
      "F1 Score: 0.824987315965127\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.09        45\n",
      "           1       0.88      1.00      0.93       305\n",
      "\n",
      "    accuracy                           0.88       350\n",
      "   macro avg       0.94      0.52      0.51       350\n",
      "weighted avg       0.89      0.88      0.82       350\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Classification Accuracy: 0.7628571428571429\n",
      "Precision: 0.837990788281486\n",
      "Recall: 0.7628571428571429\n",
      "F1 Score: 0.7914234734261836\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.53      0.37        45\n",
      "           1       0.92      0.80      0.85       305\n",
      "\n",
      "    accuracy                           0.76       350\n",
      "   macro avg       0.60      0.67      0.61       350\n",
      "weighted avg       0.84      0.76      0.79       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to convert to different color spaces and extract features\n",
    "def extract_color_space_features(image, color_space):\n",
    "    if color_space == 'HSV':\n",
    "        converted_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    elif color_space == 'LAB':\n",
    "        converted_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    elif color_space == 'YCbCr':\n",
    "        converted_image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported color space\")\n",
    "    return extract_color_features(converted_image)\n",
    "\n",
    "# Extract features from different color spaces\n",
    "color_spaces = ['HSV', 'LAB', 'YCbCr']\n",
    "for color_space in color_spaces:\n",
    "    color_space_features_list = [extract_color_space_features(image, color_space) for image in images]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(color_space_features_list, numeric_labels, test_size=0.2, random_state=42)\n",
    "    print(f\"\\nEvaluating {color_space} Color Space Features\")\n",
    "    for clf in [SVC(kernel='linear'), RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "                GradientBoostingClassifier(n_estimators=100, random_state=42), AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "                DecisionTreeClassifier(random_state=42), LogisticRegression(), GaussianNB()]:\n",
    "        train_and_evaluate_model(X_train, X_test, y_train, y_test, clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
